# Discord Bot Configuration Example
# Copy this to .env and adjust values


# Load environment variables

# Discord
DISCORD_TOKEN=
COMMAND_PREFIX=!

# Ollama
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2
OLLAMA_TEMPERATURE=1.17
OLLAMA_MAX_TOKENS=500
OLLAMA_MIN_P=0.075
OLLAMA_TOP_K=50
OLLAMA_REPEAT_PENALTY=1.1

# Advanced Sampling (SillyTavern-style)
LLM_FREQUENCY_PENALTY=0.0
LLM_PRESENCE_PENALTY=0.0
LLM_TOP_P=1.0

# LLM Provider (ollama or openrouter)
LLM_PROVIDER=ollama

# OpenRouter
OPENROUTER_API_KEY=
OPENROUTER_MODEL=nousresearch/hermes-3-llama-3.1-405b
OPENROUTER_URL=https://openrouter.ai/api/v1
OPENROUTER_TIMEOUT=180
OPENROUTER_STREAM_TIMEOUT=180

# Thinking/Decision Model (cheap/fast model for internal decisions like spam detection, routing)
THINKING_MODEL=
THINKING_MODEL_PROVIDER=

# Chat
CLEAN_THINKING_OUTPUT=true
CHAT_HISTORY_ENABLED=true
CHAT_HISTORY_MAX_MESSAGES=100
CONTEXT_MESSAGE_LIMIT=20
MAX_CONTEXT_TOKENS=8192

# Model specific context limits (override MAX_CONTEXT_TOKENS)
AUTO_REPLY_ENABLED=false
AUTO_REPLY_CHANNELS=
AUTO_REPLY_WITH_VOICE=true

# Conversation Session Settings
CONVERSATION_TIMEOUT=300

# --- Persona Settings ---
CHARACTERS_DIR=./prompts/characters

# List of active character card filenames in prompts/characters/

# If empty, loads ALL available characters

# Probability (0.0 to 1.0) that ANY bot will respond to a message

# 1.0 = Always respond (if selected)

# Scaled down to 1/6th effectively if we split probability or just use this as a gate

# The user asked for "1/6 current response rate"

# If we have 6 bots and want them to effectively respond at 1/6th rate EACH,

# we can treat them as independent agents or just route 1/6th of messages to each.

# Let's set a global gate.

# Specific weights for persona selection (optional)

# Default is equal 1/N chance for each active persona

# System Prompt / Personality
SYSTEM_PROMPT_FILE=./prompts/default.txt
SYSTEM_PROMPT=

# AI-First Persona System
USE_PERSONA_SYSTEM=true
CHARACTER=dagoth_ur
FRAMEWORK=neuro

# RAG (Retrieval-Augmented Generation)
RAG_ENABLED=false
RAG_VECTOR_STORE=./data/vector_store
RAG_DOCUMENTS_PATH=./data/documents
RAG_TOP_K=3
RAG_IN_CHAT=true
ANONYMIZED_TELEMETRY=false

# MCP (Model Context Protocol) - ARCHIVED (service never implemented)

# MCP_ENABLED: bool = os.getenv("MCP_ENABLED", "false").lower() == "true"

# MCP_SERVER_URL: str = os.getenv("MCP_SERVER_URL", "http://localhost:8080")

# User Profiles
USER_PROFILES_ENABLED=true
USER_PROFILES_PATH=./data/user_profiles
USER_PROFILES_AUTO_LEARN=true
USER_AFFECTION_ENABLED=true
USER_CONTEXT_IN_CHAT=true

# Web Search
WEB_SEARCH_ENABLED=true
WEB_SEARCH_ENGINE=duckduckgo
WEB_SEARCH_MAX_RESULTS=3

# Voice/TTS
TTS_ENGINE=kokoro_api

# Kokoro TTS Settings
KOKORO_VOICE=am_adam
KOKORO_SPEED=1.0
KOKORO_API_URL=http://localhost:8880
KOKORO_VOICE_CHIEF=am_onyx
KOKORO_VOICE_ARBY=bm_george

# Supertonic TTS Settings
SUPERTONIC_VOICE=M1
SUPERTONIC_STEPS=5
SUPERTONIC_SPEED=1.05

# RVC
RVC_ENABLED=false
RVC_MODE=webui
RVC_MODEL_PATH=./data/voice_models
DEFAULT_RVC_MODEL=GOTHMOMMY
RVC_DEVICE=cpu
RVC_WEBUI_URL=http://localhost:7865
RVC_PITCH_SHIFT=0
RVC_PROTECT=0.33
RVC_INDEX_RATE=0.75

# Audio
AUDIO_BITRATE=96
AUDIO_SAMPLE_RATE=48000

# Paths

# Memory Management
MEMORY_CLEANUP_ENABLED=true
MEMORY_CLEANUP_INTERVAL_HOURS=6
MAX_TEMP_FILE_AGE_HOURS=24
MAX_HISTORY_AGE_DAYS=30

# Response Streaming
RESPONSE_STREAMING_ENABLED=true
STREAM_UPDATE_INTERVAL=1.0

# Conversation Summarization
CONVERSATION_SUMMARIZATION_ENABLED=true
AUTO_SUMMARIZE_THRESHOLD=30
STORE_SUMMARIES_IN_RAG=true

# Voice Activity Detection (STT)
STT_ENGINE=whisper

# Whisper STT Settings
WHISPER_ENABLED=false
WHISPER_MODEL_SIZE=base
WHISPER_DEVICE=auto
WHISPER_LANGUAGE=en
WHISPER_SILENCE_THRESHOLD=1.0
MAX_RECORDING_DURATION=30

# Parakeet STT Settings
PARAKEET_ENABLED=false
PARAKEET_API_URL=http://localhost:8890
PARAKEET_MODEL=nvidia/parakeet-tdt-0.6b-v3
PARAKEET_DEVICE=auto
PARAKEET_LANGUAGE=en

# Enhanced Voice Listener Settings
VOICE_ENERGY_THRESHOLD=500
VOICE_BOT_TRIGGER_WORDS=bot,assistant,hey,help,question

# Ambient Mode Settings
AMBIENT_MODE_ENABLED=true
AMBIENT_CHANNELS=
AMBIENT_IGNORE_USERS=

# Global user ignore list
IGNORED_USERS=
AMBIENT_LULL_TIMEOUT=300
AMBIENT_MIN_INTERVAL=600
AMBIENT_CHANCE=0.3

# Proactive Engagement Settings
PROACTIVE_ENGAGEMENT_ENABLED=true
PROACTIVE_MIN_MESSAGES=3
PROACTIVE_COOLDOWN=180

# Naturalness Settings
NATURALNESS_ENABLED=true
REACTIONS_ENABLED=true
REACTIONS_CHANCE_MULTIPLIER=1.0
ACTIVITY_AWARENESS_ENABLED=true
ACTIVITY_COMMENT_CHANCE=0.1
ACTIVITY_COOLDOWN_SECONDS=300

# Natural Timing Settings
NATURAL_TIMING_ENABLED=true
NATURAL_TIMING_MIN_DELAY=0.5
NATURAL_TIMING_MAX_DELAY=2.0

# --- Persona & Behavior Enhancement Features (Phase 1 & 2) ---
# 18 AI enhancements for truly adaptive personas
# All features are production-ready with exceptional performance (<5ms total overhead)

# T1-T2: Dynamic Mood System
# Enables emotional state tracking (neutral, excited, frustrated, sad, bored, curious)
# Moods affect response tone, reactions, and engagement probability
# Performance: <0.01ms overhead per message
MOOD_SYSTEM_ENABLED=true
MOOD_UPDATE_FROM_INTERACTIONS=true
MOOD_TIME_BASED=true
MOOD_DECAY_MINUTES=30
MOOD_MAX_INTENSITY_SHIFT=0.1

# T3-T4: Context-Aware Response Length
# Automatically adjusts verbosity based on conversation context
# Quick replies get brief responses, complex questions get detailed answers
# Configured per-persona in character JSON (verbosity_by_context)
# No config needed - always active

# T5-T6: Persona Memory Isolation
# Each persona maintains separate user profiles - no memory bleed
# Profiles stored in: data/profiles/{persona_id}/{user_id}.json
# Performance: 0.33ms per profile access
USER_PROFILES_PATH=./data/user_profiles

# T7-T8: Curiosity-Driven Follow-Up Questions
# Bot asks natural follow-up questions based on curiosity level
# Cooldowns prevent spamming, topic memory prevents repetition
# Performance: 1.45ms per question generation
CURIOSITY_ENABLED=true
CURIOSITY_INDIVIDUAL_COOLDOWN_SECONDS=300
CURIOSITY_WINDOW_LIMIT_SECONDS=900
CURIOSITY_TOPIC_MEMORY_SIZE=20

# T9-T10: Topic Interest Filtering
# Personas engage more with topics they care about
# Configured per-persona in character JSON (topic_interests, topic_avoidances)
# +30% engagement on interests, -100% on avoidances
# Performance: 0.05ms per message
# No config needed - configured in persona files

# T11-T12: Adaptive Ambient Timing
# Learns channel activity patterns and adjusts engagement timing
# Reduces spam in high-frequency channels, increases in quiet channels
ADAPTIVE_TIMING_ENABLED=true
ADAPTIVE_TIMING_LEARNING_WINDOW_DAYS=7
CHANNEL_ACTIVITY_PROFILE_PATH=./data/channel_activity_profiles.json

# T13-T14: Character Evolution System
# Personas evolve through milestones (50, 100, 500, 1000, 5000 messages)
# Unlocks new behaviors, tone shifts, and knowledge over time
PERSONA_EVOLUTION_ENABLED=true
PERSONA_EVOLUTION_PATH=./data/persona_evolution

# T15-T16: Persona Conflict System
# Creates dynamic tension between personas on specific topics
# Conflicts escalate when triggers mentioned, decay over time
PERSONA_CONFLICTS_ENABLED=true
CONFLICT_DECAY_RATE=0.1
CONFLICT_ESCALATION_AMOUNT=0.2

# T17-T18: Activity-Based Persona Switching
# Routes messages to personas based on user Discord activities
# Gaming activity → gaming persona, music activity → music persona
# Performance: <0.001ms per routing decision
ACTIVITY_ROUTING_ENABLED=true
ACTIVITY_ROUTING_PRIORITY=100

# T19-T20: Framework Blending
# Dynamically adapts personality based on context
# Blends multiple frameworks (e.g., analytical + caring for support questions)
# Configured per-persona in character JSON (framework_blending)
# Performance: <10ms when blending active
# No config needed - configured in persona files

# T21-T22: Emotional Contagion
# Bot mirrors or supports user's emotional state
# Detects prolonged sadness → becomes more empathetic
# Detects excitement → becomes more enthusiastic
# Configured per-persona in character JSON (emotional_contagion)
# Performance: <1ms per message
# No config needed - configured in persona files

# T25-T26: Semantic Lorebook Triggering
# Enhanced lorebook matching using semantic similarity (sentence-transformers)
# Falls back to keyword matching for compatibility (<100ms per search)
SEMANTIC_LOREBOOK_ENABLED=true
SEMANTIC_LOREBOOK_THRESHOLD=0.65  # Cosine similarity threshold (0.0-1.0)
SEMANTIC_LOREBOOK_CACHE_SIZE=1000  # Max embeddings to cache (LRU eviction)

# T23-T24: Real-Time Analytics Dashboard
# Web-based monitoring interface for persona metrics and performance
# Requires FastAPI and uvicorn (auto-installed with dependencies)
ANALYTICS_DASHBOARD_ENABLED=false
ANALYTICS_DASHBOARD_PORT=8080
ANALYTICS_API_KEY=change_me_in_production  # CHANGE THIS for security!

# Self-Awareness Settings
SELF_AWARENESS_ENABLED=true
HESITATION_CHANCE=0.15
META_COMMENT_CHANCE=0.10
SELF_CORRECTION_ENABLED=true

# Reminders
REMINDERS_ENABLED=true
MAX_REMINDERS_PER_USER=10

# Vision/Image Understanding
VISION_ENABLED=true
VISION_MODEL=llava

# Trivia Games
TRIVIA_ENABLED=true

# Natural Language Understanding
INTENT_RECOGNITION_ENABLED=true
NATURAL_LANGUAGE_REMINDERS=true

# Notes
NOTES_ENABLED=true

# Logging Configuration
LOG_LEVEL=INFO
LOG_TO_FILE=true
LOG_FILE_PATH=logs/bot.log
LOG_MAX_BYTES=10485760
LOG_BACKUP_COUNT=5
LOG_FORMAT=text  # json or text (text for development, json for production)
LOG_COMPRESS=true  # Compress old log files with gzip

# Performance Logging
LOG_PERFORMANCE=true
LOG_LLM_REQUESTS=true
LOG_TTS_REQUESTS=true

# Chat Timing Configuration
TYPING_INDICATOR_MIN_DELAY=0.5  # Minimum typing delay in seconds
TYPING_INDICATOR_MAX_DELAY=2.0  # Maximum typing delay in seconds

# Response Token Limits by Context
RESPONSE_TOKENS_VERY_SHORT=50
RESPONSE_TOKENS_SHORT=100
RESPONSE_TOKENS_MEDIUM=200
RESPONSE_TOKENS_LONG=350
RESPONSE_TOKENS_VERY_LONG=500

# Analytics & Monitoring Configuration
ANALYTICS_WEBSOCKET_UPDATE_INTERVAL=2.0  # WebSocket update interval in seconds
ERROR_SPIKE_WINDOW_SECONDS=300  # Time window for error spike detection (5 minutes)

# Memory & Profile Configuration
PROFILE_SAVE_INTERVAL_SECONDS=60  # Profile auto-save interval in seconds
RAG_RELEVANCE_THRESHOLD=0.5  # Minimum relevance score for RAG results (0.0-1.0)

# Persona Behavior Timeouts
PERSONA_STICKY_TIMEOUT=300  # Sticky persona timeout in seconds (5 minutes)
PERSONA_FOLLOWUP_COOLDOWN=300  # Cooldown between followup questions in seconds (5 minutes)
PERSONA_EVOLUTION_MILESTONES=50,100,500,1000,5000  # Message count milestones for evolution

# Mood System Advanced Configuration
MOOD_CHECK_INTERVAL_SECONDS=60  # How often to check/update mood in seconds
MOOD_BOREDOM_TIMEOUT_SECONDS=600  # Time before boredom kicks in (10 minutes)

# Web Search Configuration
WEB_SEARCH_RATE_LIMIT_DELAY=2.0  # Minimum delay between search requests in seconds

# Service Cleanup Timeouts
SERVICE_CLEANUP_TIMEOUT=2.0  # Timeout for service cleanup operations in seconds

# Metrics Configuration
METRICS_ENABLED=true
METRICS_SAVE_INTERVAL_MINUTES=60
METRICS_RETENTION_DAYS=30

# Performance Optimization Settings
USE_STREAMING_FOR_LONG_RESPONSES=true
STREAMING_TOKEN_THRESHOLD=300
DYNAMIC_MAX_TOKENS=false

# LLM Response Caching
LLM_CACHE_ENABLED=true
LLM_CACHE_MAX_SIZE=1000
LLM_CACHE_TTL_SECONDS=3600

# LLM Model Fallback (LiteLLM-style)
LLM_FALLBACK_ENABLED=false
LLM_FALLBACK_MODELS=

# Example: "x-ai/grok-beta:free,anthropic/claude-3.5-sonnet:paid"

# Validate Ollama parameters

# Validate chat history settings

# Validate timing settings

# Validate probability values

# Create necessary directories with error handling

# Validate on import