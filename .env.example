# Discord Configuration
DISCORD_TOKEN=your_discord_bot_token_here
COMMAND_PREFIX=!

# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2
OLLAMA_TEMPERATURE=1.17
OLLAMA_MAX_TOKENS=500
OLLAMA_MIN_P=0.075
OLLAMA_TOP_K=50
OLLAMA_REPEAT_PENALTY=1.1

# LLM Provider Selection
LLM_PROVIDER=ollama  # "ollama" or "openrouter"

# OpenRouter Configuration (when LLM_PROVIDER=openrouter)
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_MODEL=nousresearch/hermes-3-llama-3.1-405b
OPENROUTER_URL=https://openrouter.ai/api/v1
OPENROUTER_TIMEOUT=180  # API timeout in seconds (default: 180)
OPENROUTER_STREAM_TIMEOUT=180  # Streaming timeout in seconds (default: 180)

# Advanced LLM Sampling (for both Ollama and OpenRouter)
LLM_FREQUENCY_PENALTY=0.0
LLM_PRESENCE_PENALTY=0.0
LLM_TOP_P=1.0

# Chat Configuration
CHAT_HISTORY_ENABLED=true
CHAT_HISTORY_MAX_MESSAGES=20
AUTO_REPLY_ENABLED=false
AUTO_REPLY_CHANNELS=  # Comma-separated channel IDs
AUTO_REPLY_WITH_VOICE=true
CONVERSATION_TIMEOUT=300

# System Prompt
SYSTEM_PROMPT_FILE=./prompts/default.txt
SYSTEM_PROMPT=

# AI-First Persona System (NEW!)
# Combines character identity with behavioral framework
USE_PERSONA_SYSTEM=true
CHARACTER=dagoth_ur  # Available: dagoth_ur (more in prompts/characters/)
FRAMEWORK=neuro      # Available: neuro, assistant (more in prompts/frameworks/)

# RAG
RAG_ENABLED=false
RAG_VECTOR_STORE=./data/vector_store
RAG_DOCUMENTS_PATH=./data/documents
RAG_TOP_K=3

# User Profiles
USER_PROFILES_ENABLED=true
USER_PROFILES_PATH=./data/user_profiles
USER_PROFILES_AUTO_LEARN=true
USER_AFFECTION_ENABLED=true
USER_CONTEXT_IN_CHAT=true

# TTS
# Options: "edge" (cloud), "kokoro" (local CPU), "kokoro_api" (local GPU via API), "supertonic" (ultra-fast)
TTS_ENGINE=edge
DEFAULT_TTS_VOICE=en-US-AriaNeural
TTS_RATE=+0%
TTS_VOLUME=+0%

# Kokoro TTS Settings
# - "kokoro" = In-process CPU inference (~300MB RAM)
# - "kokoro_api" = GPU-accelerated via Kokoro-FastAPI (10x faster!)
KOKORO_VOICE=am_adam
KOKORO_SPEED=1.0
KOKORO_API_URL=http://localhost:8880  # For TTS_ENGINE=kokoro_api
KOKORO_VOICE_CHIEF=am_onyx  # Per-persona voice overrides
KOKORO_VOICE_ARBY=bm_george

# Supertonic TTS (Ultra-fast on-device TTS - 167x real-time speed)
# Voice options: M1, M2 (male), F1, F2 (female), or aliases: "male", "female", "man", "woman"
SUPERTONIC_VOICE=M1
SUPERTONIC_STEPS=5  # Denoising steps (1-20, higher = better quality but slower)
SUPERTONIC_SPEED=1.05  # Speech speed multiplier (0.5-2.0)

# RVC
RVC_ENABLED=false
RVC_MODE=webui  # "inferpy" or "webui"
RVC_DEVICE=cpu
RVC_MODEL_PATH=./data/voice_models
DEFAULT_RVC_MODEL=GOTHMOMMY
RVC_WEBUI_URL=http://localhost:7865

# Audio
AUDIO_BITRATE=96
AUDIO_SAMPLE_RATE=48000

# Web Search (optional)
WEB_SEARCH_ENABLED=false
WEB_SEARCH_ENGINE=duckduckgo
WEB_SEARCH_MAX_RESULTS=3

# MCP (Model Context Protocol - optional)
MCP_ENABLED=false
MCP_SERVER_URL=http://localhost:8080

# ==========================================
# NEW FEATURES
# ==========================================

# Memory Management
MEMORY_CLEANUP_ENABLED=true
MEMORY_CLEANUP_INTERVAL_HOURS=6
MAX_TEMP_FILE_AGE_HOURS=24
MAX_HISTORY_AGE_DAYS=30

# Response Streaming
RESPONSE_STREAMING_ENABLED=true
STREAM_UPDATE_INTERVAL=1.0

# Conversation Summarization
CONVERSATION_SUMMARIZATION_ENABLED=true
AUTO_SUMMARIZE_THRESHOLD=30
STORE_SUMMARIES_IN_RAG=true

# Voice Activity Detection (Speech-to-Text)
# Choose your STT engine: "whisper" or "parakeet"
STT_ENGINE=whisper

# Whisper STT (OpenAI - 99 languages, slower but multilingual)
# Install: pip install faster-whisper
WHISPER_ENABLED=false
WHISPER_MODEL_SIZE=base
WHISPER_DEVICE=auto
WHISPER_LANGUAGE=en
WHISPER_SILENCE_THRESHOLD=2.0
MAX_RECORDING_DURATION=30

# Whisper model recommendations:
# - tiny: Fast, 400MB RAM
# - base: Recommended, 500MB RAM
# - small: Better accuracy, 1GB RAM
# - medium: High accuracy, 2.5GB RAM
# - large: Best accuracy, 5GB RAM (GPU recommended)

# Parakeet STT (NVIDIA - 25 European languages, 10x faster, better noise handling)
# Install: uv pip install nemo_toolkit['asr']
PARAKEET_ENABLED=false
PARAKEET_MODEL=nvidia/parakeet-tdt-0.6b-v3
PARAKEET_DEVICE=auto
PARAKEET_LANGUAGE=en

# Parakeet advantages:
# - 10x faster than Whisper for European languages
# - Better accuracy in noisy environments (Discord reality!)
# - Automatic punctuation and capitalization
# - Fewer deletion/insertion errors
# - ~2GB VRAM on GPU, works on CPU too
# - Supports: en, de, es, fr, it, pt, pl, nl, ru, uk, cs, ro, hu, sk, bg, hr, sl, lt, lv, et, fi, sv, da, no, el

# Enhanced Voice Listener (Smart Response Triggers)
VOICE_ENERGY_THRESHOLD=500
VOICE_BOT_TRIGGER_WORDS=bot,assistant,hey,help,question

# Ambient Mode (Bot chimes in naturally)
AMBIENT_MODE_ENABLED=true
AMBIENT_CHANNELS=  # Comma-separated channel IDs (empty = disabled)
AMBIENT_IGNORE_USERS=  # Comma-separated user IDs to ignore (no reactions/activity comments)
AMBIENT_LULL_TIMEOUT=300  # Seconds of silence before lull trigger
AMBIENT_MIN_INTERVAL=600  # Min seconds between ambient messages
AMBIENT_CHANCE=0.3  # Chance to trigger (0.0-1.0)

# Proactive Engagement (Bot jumps in when interested in topics)
PROACTIVE_ENGAGEMENT_ENABLED=true  # Bot jumps into conversations about interesting topics
PROACTIVE_MIN_MESSAGES=3  # Minimum messages before bot can jump in
PROACTIVE_COOLDOWN=180  # Seconds between proactive engagements (3 minutes)

# Naturalness Features (Makes the bot feel more alive)
NATURALNESS_ENABLED=true
REACTIONS_ENABLED=true  # Bot reacts with emojis to messages
REACTIONS_CHANCE_MULTIPLIER=1.0  # Adjust reaction frequency (0.5 = half, 2.0 = double)
ACTIVITY_AWARENESS_ENABLED=true  # Comment on user activities (games, streaming, Spotify)
ACTIVITY_COMMENT_CHANCE=0.3  # Chance to comment on activity changes (0.0-1.0)
ACTIVITY_COOLDOWN_SECONDS=300  # Cooldown before commenting on same activity type again (prevents spam when changing songs)

# Natural Timing (Variable response delays for more natural feel)
NATURAL_TIMING_ENABLED=true
NATURAL_TIMING_MIN_DELAY=0.5  # Minimum delay in seconds
NATURAL_TIMING_MAX_DELAY=2.0  # Maximum delay in seconds

# Mood System (Dynamic emotional states)
MOOD_SYSTEM_ENABLED=true
MOOD_UPDATE_FROM_INTERACTIONS=true  # Auto-update mood based on user interactions
MOOD_TIME_BASED=true  # Use time of day to influence mood

# Self-Awareness (Meta humor and self-referential comments)
SELF_AWARENESS_ENABLED=true
HESITATION_CHANCE=0.15  # Chance to add "um", "uh", etc. (0.0-1.0)
META_COMMENT_CHANCE=0.10  # Chance for self-aware comments (0.0-1.0)
SELF_CORRECTION_ENABLED=true  # Allow bot to correct itself mid-response

# Reminders
REMINDERS_ENABLED=true
MAX_REMINDERS_PER_USER=10

# Natural Language Understanding
INTENT_RECOGNITION_ENABLED=true  # Enable understanding natural language commands
NATURAL_LANGUAGE_REMINDERS=true  # Allow setting reminders via natural language

# ===================================================================
# Logging Configuration
# ===================================================================
# DEBUG mode enables enhanced metrics:
#   - Saves detailed metrics every 10 minutes (vs 60 in INFO)
#   - Tracks last 500 responses (vs 100 in INFO)
#   - Logs every request with full details to JSON
#   - Perfect for optimization work!
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_TO_FILE=true  # Save logs to file
LOG_FILE_PATH=logs/bot.log  # Log file location
LOG_MAX_BYTES=10485760  # Max log file size (10MB default)
LOG_BACKUP_COUNT=5  # Number of backup log files to keep

# Performance Logging (what to log)
LOG_PERFORMANCE=true  # Log general performance metrics
LOG_LLM_REQUESTS=true  # Log every LLM API request with timing
LOG_TTS_REQUESTS=true  # Log every TTS request with timing

# ===================================================================
# Metrics Configuration
# ===================================================================
METRICS_ENABLED=true  # Enable metrics collection and saving
METRICS_SAVE_INTERVAL_MINUTES=60  # Save metrics every N minutes (default: 60 = hourly)
METRICS_RETENTION_DAYS=30  # Keep metrics files for N days

# ===================================================================
# Performance Optimization Settings
# ===================================================================
USE_STREAMING_FOR_LONG_RESPONSES=true  # Use streaming only for long responses
STREAMING_TOKEN_THRESHOLD=300  # Use streaming if estimated response > N tokens
DYNAMIC_MAX_TOKENS=false  # Automatically adjust max_tokens based on query type
